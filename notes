- To use default db for queue run:
php artisan queue:table
php artisan migrate
QUEUE_CONNECTION=database

We must start the worker:
php artisan queue:work (run from inside laradock)
* it will now scan the db to look for jobs and will start processing them.
* a worker will execute jobs one by one which can take a long time. However we can run multiple queues at tthe same time. Queues can be given
priority and specific job types can be assigned to a specific queue:
- php artisan queue:work --queue=payments,default (payments has priority because it is first)
- \App\Jobs\ProcessPayment::dispatch()->onQueue('payments');

- $timeout can be used to ensure jobs don't hang if, for wxample, a third party api is unresponsive
- use retryUntil for a time based retry. it will retry repeatedly until time expires.
- $backoff = 2 - waits for 2 secs between each retry

* if a job exhausts all if it's retries laravel stores the failed job in the db. we can grab the uuid and manually retry using pph artisan queue:retry {uuid}
* using the return $this->release() in handle will release job back to the queue to be retried if, for example, a api call has hit a rate limit
the number of $tries will determine how many release() retries are allowed.
* laravel counts an attempt as a retry whether the job was retried as a result of a release() or an exception. we can tell laravel
to count them separately by using the $maxExceptions prop.
* the failed() ethod is run when a job failed.

* job workflows are sequential jobs where subsequent jobs will not execute until the previous one has completed
* batches are non-sequetial batches:
- php artisan queue:batches-table (then migrate)
- add Batchable trait to the job classes

* if a batch job is failed the rest of the jobs in the batch will be cancelled. to stop this behaviour we can use the
allowFailures() method

* a race condition is where two processes try to make changes to the same resource and the same time. We can use Lock functions
of laravel to lock the logic inside the closure

* WithoutOverlapping will release jobs back or they will fail if they exceed the max amount. jobs will be placed back in queue even if there
are multiple instances of the same job in the queue whereupon they will then be executed sequentially.
* To ensure that there is only ever one isntance of the same job in the queue we can implement the ShouldBeUnique on the class
*ShouldBeUniqueUntilProcessing interface can prevent dispatching until the job has started processing.

* the more dependencies we pass to the job the more overhead will be created. this can have implications on high volume
applications. the deps have to be serialized and deserialized. it can consume a lot of resources. we can use app()->make('deployer')
to inject dependencies irectly into the job handler without it having to be serialized etc when it is passed via the constructor of
the job.

* we can pass a dependency directly to the constructor of the job to make sure the job gets the latest state of the dep at the time
at which the job was generated, not when it was picked up by the worker.

* we can use the ShouldBeEncypted interface to get laravel to encrypt the pay load of the job

* in the real world workers can crash or stop for whatever reason. we can user supervisor to monitor and keep the worker alive at all
times. It can be easily used in forge. We can get forge to restart queue when deploying by adding the code to the Deploy Script command in
forge.

* we can use the sudo supervisorctl stop worker-xxx:* command to gracefully stop all jobs before the start command is subsequently ran. this means
that any db changes that ar emade as a result of teh deployment won't cause any failures on the jobs which were already present when the
db changes kicked in. You can get the worker names from forge support. Using stop and start commands rather than the restart can mean that
any jobs currently running can slow down deployment. use the restart command if you are sure there are no changes to the db which will cause
any current jobs to fail.

* we can scale workers by adding more workers to the same server by using supervisor to start more workers when specific programmes start
Also it can start new workers on a cron based schedule.

* we can start jobs in supervisor and use the --stop-when-empty queue flag to tell the workers to stop when they are empty. we can also
use the --max-time=3600 to stop them after a specific amount of time.

Horizon
--------
in more complex scenarios you may need to scale workers handling specific queues. if you are using the redis queue driver
ypu can use horizon can be used for that. It gives more granular control over more complex queueing needs and should be considered for
complex queue handling.
